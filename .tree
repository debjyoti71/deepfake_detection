deepfake_detection/
│
├── data/                                 # All datasets and preprocessed features
│   ├── raw/                              # Original videos
│   │   ├── RealVideo-RealAudio/          # Category A (Real Video + Real Audio) ✅
│   │   │   ├── African/men/id00076/      # Example ID folder
│   │   │   │   ├── video1.mp4            # Original video
│   │   │   │   ├── video1.txt            # Transcript of audio ✅
│   │   │   │   ├── video2.mp4
│   │   │   │   ├── video2.txt
│   │   │   │   └── ...
│   │   │   └── women/...
│   │   └── Asian/...
│   │
│   │   ├── RealVideo-FakeAudio/          # Category B (Real Video + Fake Audio) ✅
│   │   │   ├── African/men/id00076/*.mp4
│   │   │   └── ...
│   │   ├── FakeVideo-RealAudio/          # Category C (Fake Video + Real Audio) ✅
│   │   │   └── African/men/id00076/*.mp4
│   │   └── FakeVideo-FakeAudio/          # Category D (Fake Video + Fake Audio) ✅
│   │       └── African/men/id00076/*.mp4
│   │
│   ├── processed/                        # Preprocessed data for models
│   │   ├── frames/                        # Extracted face crops from videos ✅
│   │   │   ├── <video_id>/frame_001.jpg
│   │   │   └── ...
│   │   ├── audio/                         # Cleaned .wav audio files ✅
│   │   │   ├── <video_id>.wav
│   │   ├── audio_features/                # Mel-spectrograms / embeddings ✅
│   │   │   ├── <video_id>.npy
│   │   └── sync_data/                     # Mouth crops + audio chunks for lip-sync ✅
│   └── metadata.csv                        # Video metadata (labels, category, gender, etc.) ✅
│
├── src/                                   # Source code
│   ├── preprocessing/                     # Data preparation scripts
│   │   ├── extract_frames.py              # Extract frames from videos ✅
│   │   ├── face_detection.py              # Detect faces in frames ✅
│   │   ├── extract_audio.py               # Extract audio from videos ✅
│   │   └── feature_extraction.py          # Convert audio → features, align lips & audio ✅
│   │
│   ├── models/                            # Model definitions
│   │   ├── visual_model.py                # CNN/Transformer for frames ✅
│   │   ├── audio_model.py                 # CNN/Transformer for audio ✅
│   │   ├── sync_model.py                  # Lip-sync detection ✅
│   │   └── fusion_model.py                # Combine visual+audio+sync predictions ✅
│   │
│   ├── training/                          # Training scripts
│   │   ├── train_visual.py                # Train visual model ✅
│   │   ├── train_audio.py                 # Train audio model ✅
│   │   ├── train_sync.py                  # Train sync model ✅
│   │   ├── train_fusion.py                # Train fusion model ✅
│   │   └── utils.py                        # Shared utilities
│   │
│   ├── evaluation/                        # Model evaluation scripts
│   │   ├── evaluate.py                     # Evaluate models (visual, audio, sync, fusion) ✅
│   │   ├── metrics.py                      # Accuracy, F1, confusion matrix
│   │   └── explainability.py               # Grad-CAM, heatmaps, spectrogram visualizations ✅
│   │
│   └── api/                               # REST API for inference
│       ├── main.py                         # `/predict` endpoint ✅
│       ├── inference.py                    # Loads models & runs predictions
│       └── utils.py                        # Shared API utilities
│
├── models/                                # Saved trained model weights
│   ├── visual_model.pth ✅
│   ├── audio_model.pth ✅
│   ├── sync_model.pth ✅
│   └── fusion_model.pth ✅
│
├── notebooks/                             # Jupyter notebooks for experimentation
│   ├── EDA.ipynb                           # Exploratory Data Analysis
│   ├── Train_Visual.ipynb                  # Visual model experiments
│   └── Train_Audio.ipynb                   # Audio model experiments
│
├── results/                               # Output results
│   ├── logs/                               # Training logs (TensorBoard/W&B)
│   ├── predictions/                        # CSV/JSON predictions ✅
│   └── explainability/                     # Grad-CAM heatmaps, sync plots ✅
│
├── .tree                                  # File tree (optional)
├── requirements.txt                        # Python dependencies
├── README.md                               # Project overview
└── config.yaml                             # Configurations (paths, hyperparameters)
